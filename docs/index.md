# Visually Impaired Accessible Room

## Abstract

This project aims to develop an accessible room environment for visually impaired individuals, utilizing a depth camera, Apple Watch, and auditory feedback to provide spatial awareness and navigational guidance. The system helps users locate and retrieve objects by offering precise instructions via haptic feedback and audio cues. Our approach combines stationary depth sensing with multi-modal feedback to create a hands-free, user-friendly experience. Initial results show successful implementation of haptic feedback and ongoing development of object detection and hand tracking.

## Team

* Alex Hafemeister
* Arshia Dabiran
* Dhruv Sirohi
* Ethan Jiang

## Required Submissions

* [Proposal](https://github.com/ECEM202A/viar.github.io/blob/main/docs/proposal.md)
* [Midterm Checkpoint Presentation Slides](http://)
* [Final Presentation Slides](http://)
* [Final Report](https://github.com/ECEM202A/viar.github.io/blob/main/docs/report.md)
